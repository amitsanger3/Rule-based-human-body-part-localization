{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, json\n",
    "import random, traceback\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Faces(object):\n",
    "    \n",
    "    def __init__(self, face_cascade, face_dir, output_dir,):\n",
    "        self.face_cascade = face_cascade\n",
    "        self.image_num = 1\n",
    "        self.dir_num = 1\n",
    "        self.face_dir = face_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.image_name = 'Face'\n",
    "        self.error = []\n",
    "        \n",
    "    def face_co_ordinates(self, gray):\n",
    "        return self.face_cascade.detectMultiScale(gray, 1.2, 4)\n",
    "#         return face_classifier.detectMultiScale(gray, 1.2, 4)\n",
    "    \n",
    "    def draw_rectangle(self, image, co_ordinate):\n",
    "        x,y,w,h = co_ordinate\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        return None\n",
    "    \n",
    "    def crop_face(self, image, co_ordinate):\n",
    "        x,y,w,h = co_ordinate\n",
    "        return image[y:y+h, x:x+w]\n",
    "    \n",
    "    def all_faces(self, draw_face=False):\n",
    "        images = os.listdir(self.face_dir)\n",
    "        print(self.dir_num, self.face_dir,'  starts with: ', self.image_num,'  having images:', len(images))\n",
    "        for image_name in images:\n",
    "            if image_name[-4:] == '.jpg':\n",
    "                image = cv2.imread(os.path.join(self.face_dir, image_name))\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                co_ordinates = self.face_co_ordinates(gray)\n",
    "\n",
    "                if len(co_ordinates) > 0:\n",
    "                    for co_ordinate in co_ordinates:\n",
    "                        if draw_face:\n",
    "                            self.draw_rectangle(image, co_ordinate)\n",
    "                            cv2.imshow('Sunny', image)\n",
    "                            cv2.waitKey(500)\n",
    "                        else:\n",
    "                            try:\n",
    "                                crop_image = self.crop_face(image, co_ordinate)\n",
    "                                name = os.path.join(self.output_dir, self.image_name + str(self.image_num) +'.jpg')\n",
    "                                cv2.imwrite(name, crop_image)\n",
    "                                self.image_num += 1\n",
    "                            except:\n",
    "                                self.error.append(image_name)\n",
    "                                continue\n",
    "        print('No. of errors: ', len(self.error))\n",
    "        print('====================================================================================================')\n",
    "        data = {'Errors': self.error}\n",
    "        df = pd.DataFrame(data)\n",
    "        img_dir = self.face_dir.replace('./IMAGES/', '')\n",
    "        err_file = os.path.join(self.output_dir, 'error_'+img_dir[:-1]+'.csv')\n",
    "        df.to_csv(err_file)\n",
    "        cv2.destroyAllWindows()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_path =  r'F:\\Documents\\PROJECT\\Face\\HAARCASCADE'\n",
    "classifier = os.listdir(classifier_path)\n",
    "face_classifier = cv2.CascadeClassifier(os.path.join(classifier_path, classifier[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEW YORK CITY 2018_ WE ARE the crowds of TIMES SQUARE! [4K].mp4',\n",
       " 'Russian Beautiful Girls on Walking in Russia - Part 2.mp4',\n",
       " 'Russian Beautiful Girls Walking Street - Part 1.mp4',\n",
       " 'y2mate.com - M G ROAD CROWD WALKING  STOCK FOOTAGES_1080p.mp4',\n",
       " 'y2mate.com - Street Style Highlights  Models Off Duty SS 2019_1080pFHR.mp4',\n",
       " 'y2mate.com - WHAT EVERYONE IS WEARING IN PARIS  Paris Street Fashion_1080p.mp4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = r\"F:\\Documents\\PROJECT\\VIDEOS\\Facevids\"\n",
    "imgs = os.listdir(img_path)\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=4, kernel_size=3,stride=1,padding=1,dilation=1,groups=1,bias=True,)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4,out_channels=16, kernel_size=3,stride=1,padding=1,dilation=1,groups=1,bias=True,)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=8,out_channels=16, kernel_size=3,stride=1,padding=1,dilation=1,groups=1,bias=True,)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2*2*16*16, 128)\n",
    "        self.fc2 = nn.Linear(128, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2,2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2,2)\n",
    "        # X = F.relu(self.conv3(X))\n",
    "        # X = F.max_pool2d(X, 2,2)\n",
    "        X = X.view(-1, 16*16*2*2)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        \n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NodeCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r'F:\\Documents\\PROJECT\\Face\\FACE_CLASSIFIER_MODEL_2'\n",
    "\n",
    "test_model_path = os.path.join(model_path, \"FRS_CLASSIFIER_Model_50.net\")\n",
    "model.load_state_dict(torch.load(test_model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeCNN(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Faces(object):\n",
    "    \n",
    "    def __init__(self, face_cascade, face_dir, output_dir,):\n",
    "        self.face_cascade = face_cascade\n",
    "        self.image_num = 1\n",
    "        self.dir_num = 1\n",
    "        self.face_dir = face_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.image_name = 'Face'\n",
    "        self.error = []\n",
    "        \n",
    "    def face_co_ordinates(self, gray):\n",
    "        return self.face_cascade.detectMultiScale(gray, 1.2, 4)\n",
    "#         return face_classifier.detectMultiScale(gray, 1.2, 4)\n",
    "\n",
    "    def neck_cordinates(self, x,y,w,h):\n",
    "        return int(x+(w/8)), (y+h), int(w-(w/4)), int(h*0.4) # check this\n",
    "    \n",
    "    def upper_half_torso_cordinates(self, x,y,w,h, h1):\n",
    "        return int(x - (w/2)), (y+h+h1), 2*w, 2*h\n",
    "        \n",
    "    def lower_half_torso_cordinates(self, x,y,w,h, h_):\n",
    "        return x, y+h, w, h_\n",
    "    \n",
    "    def legs_cordinates(self, x,y,w,h, h_):\n",
    "        return x, y+h, w, 4*h_\n",
    "    \n",
    "    def foot_cordinates(self, x,y,w,h, h_):\n",
    "        return x, y+h, w, int(h_/2)\n",
    "    \n",
    "    def colors(self):\n",
    "        return (random.choice(range(0, 255)), random.choice(range(0, 255)), random.choice(range(0, 255)))\n",
    "    \n",
    "    def draw_rectangle(self, image, co_ordinate, color):\n",
    "        x,y,w,h = co_ordinate\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), color, 2)\n",
    "        return None\n",
    "    \n",
    "    def crop_face(self, image, co_ordinate):\n",
    "        x,y,w,h = co_ordinate\n",
    "        return image[y:y+h, x:x+w]\n",
    "    \n",
    "    def all_faces(self, draw_face=False):\n",
    "        images = os.listdir(self.face_dir)\n",
    "        print(self.dir_num, self.face_dir,'  starts with: ', self.image_num,'  having images:', len(images))\n",
    "        for image_name in images:\n",
    "            if image_name[-4:] == '.jpg':\n",
    "                image = cv2.imread(os.path.join(self.face_dir, image_name))\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                co_ordinates = self.face_co_ordinates(gray)\n",
    "\n",
    "                if len(co_ordinates) > 0:\n",
    "                    for co_ordinate in co_ordinates:\n",
    "                        if draw_face:\n",
    "                            x,y,w,h = co_ordinate\n",
    "                            self.draw_rectangle(image, co_ordinate)\n",
    "                            x1, y1, w1, h1 = self.neck_cordinates(x,y,w,h)\n",
    "                            self.draw_rectangle(image, (x1, y1, w1, h1))\n",
    "                            x2, y2, w2, h2 = self.upper_half_torso_cordinates(x,y,w,h,h1)\n",
    "                            self.draw_rectangle(image, (x2, y2, w2, h2))\n",
    "                            x3, y3, w3, h3 = self.lower_half_torso_cordinates(x3, y3, w3, h3, h)\n",
    "                            self.draw_rectangle(image, (x3, y3, w3, h3))\n",
    "                            x4, y4, w4, h4 = self.legs_cordinates(x3, y3, w3, h3, h_)\n",
    "                            self.draw_rectangle(image, (x4, y4, w4, h4))\n",
    "                            x5, y5, w5, h5 = self.foot_cordinates(x4, y4, w4, h4, h_)\n",
    "                            self.draw_rectangle(image, (x5, y5, w5, h5))\n",
    "                            cv2.imshow('Sunny', image)\n",
    "                            cv2.waitKey(500)\n",
    "                        else:\n",
    "                            break\n",
    "#                             try:\n",
    "#                                 crop_image = self.crop_face(image, co_ordinate)\n",
    "#                                 name = os.path.join(self.output_dir, self.image_name + str(self.image_num) +'.jpg')\n",
    "#                                 cv2.imwrite(name, crop_image)\n",
    "#                                 self.image_num += 1\n",
    "#                             except:\n",
    "#                                 self.error.append(image_name)\n",
    "#                                 continue\n",
    "        print('No. of errors: ', len(self.error))\n",
    "        print('====================================================================================================')\n",
    "        data = {'Errors': self.error}\n",
    "        df = pd.DataFrame(data)\n",
    "        img_dir = self.face_dir.replace('./IMAGES/', '')\n",
    "        err_file = os.path.join(self.output_dir, 'error_'+img_dir[:-1]+'.csv')\n",
    "        df.to_csv(err_file)\n",
    "        cv2.destroyAllWindows()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceIdentifier(Faces):\n",
    "    \n",
    "    def __init__(self, input_image_path, face_cascade, face_dir, output_dir):\n",
    "        Faces.__init__(self, face_cascade, face_dir, output_dir)\n",
    "        self.makedir(face_dir)\n",
    "        self.makedir(output_dir)\n",
    "        self.input_image_path = input_image_path\n",
    "        self.video_num = 1\n",
    "        self.is_face = False\n",
    "\n",
    "    @staticmethod\n",
    "    def makedir(dir_path):\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        \n",
    "    @staticmethod\n",
    "    def resize_with_aspect_ratio(img, width=640, inter=cv2.INTER_AREA):\n",
    "        h,w = img.shape[:2]\n",
    "        r = width/float(w)\n",
    "        dim = width, int(h*r)\n",
    "        return cv2.resize(img, dim, interpolation=inter)\n",
    "        \n",
    "    def get_face(self, draw_face=False):\n",
    "        for img_name  in tqdm_notebook(os.listdir(self.input_image_path)):\n",
    "            image_path = os.path.join(self.input_image_path, img_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                try:\n",
    "                    image = np.uint8(image)\n",
    "                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                co_ordinates = self.face_co_ordinates(gray)\n",
    "\n",
    "                if len(co_ordinates) > 0:\n",
    "                    for co_ordinate in co_ordinates:\n",
    "                        if draw_face:\n",
    "                            color = self.colors()\n",
    "                            x,y,w,h = co_ordinate\n",
    "                            try:\n",
    "                                crop_image = self.crop_face(image, co_ordinate)\n",
    "                                name = os.path.join(self.face_dir, self.image_name + str(self.image_num) +'.jpg')\n",
    "                                cv2.imwrite(name, crop_image)\n",
    "                                self.image_num += 1\n",
    "                            except:\n",
    "                                print(traceback.print_exc())\n",
    "                            try:\n",
    "                                x_ = cv2.resize(cv2.cvtColor(crop_image, cv2.COLOR_BGR2GRAY), (2*16, 32))/255\n",
    "                                x_ = x_.astype(np.float32)\n",
    "                                x_ = torch.tensor(x_)\n",
    "                                x_ = x_.view((1,1,32,16*2))\n",
    "                                pred = model(x_)\n",
    "\n",
    "                                pred = int(pred.argmax().item())\n",
    "                                \n",
    "                                if pred == 1:\n",
    "                                    if os.path.exists(image_path):\n",
    "                                        shutil.move(image_path, os.path.join(self.output_dir, img_name))\n",
    "                            except:\n",
    "                                print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path=r\"F:\\Documents\\PROJECT\\GARMENTS\\CROQUIE_DC\\DownloadDataset\\Fashion1000\"\n",
    "face_cascade=face_classifier\n",
    "face_dir=r\"F:\\Documents\\PROJECT\\GARMENTS\\CROQUIE_DC\\DownloadDataset\\Fashion1000_face\"\n",
    "output_dir=r\"F:\\Documents\\PROJECT\\GARMENTS\\CROQUIE_DC\\DownloadDataset\\Fashion1000_OP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\AppData\\Local\\Temp\\ipykernel_10484\\3084088691.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for img_name  in tqdm_notebook(os.listdir(self.input_image_path)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54ed1a7323f4de6987b8c0ecbc64cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FaceIdentifier(input_image_path, face_cascade, face_dir, output_dir).get_face(draw_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"F:\\Documents\\PROJECT\\ANALYSIS\\twitter\\VOGUE\"\n",
    "main_dir = r\"F:\\Documents\\PROJECT\\GARMENTS\\CROQUIE_DC\\DownloadDataset\\VOGUE\"\n",
    "if not os.path.exists(main_dir): os.makedirs(main_dir)\n",
    "\n",
    "for img_name in random.choices(os.listdir(output_dir), k=10):\n",
    "    try:\n",
    "        shutil.move(os.path.join(output_dir, img_name), os.path.join(main_dir, img_name))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFace(Faces):\n",
    "    \n",
    "    def __init__(self, video_path, face_cascade, face_dir, output_dir):\n",
    "        Faces.__init__(self, face_cascade, face_dir, output_dir)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        self.video = video_path\n",
    "        self.video_num = 1\n",
    "        self.is_face = False\n",
    "        \n",
    "    @staticmethod\n",
    "    def resize_with_aspect_ratio(img, width=640, inter=cv2.INTER_AREA):\n",
    "        h,w = img.shape[:2]\n",
    "        r = width/float(w)\n",
    "        dim = width, int(h*r)\n",
    "        return cv2.resize(img, dim, interpolation=inter)\n",
    "        \n",
    "    def get_video_face(self, draw_face=False):\n",
    "        \n",
    "        cap = cv2.VideoCapture(self.video)\n",
    "        print(self.video_num, 'Video Running -->', self.video)\n",
    "        while True:\n",
    "            self.is_face = False\n",
    "            success, image = cap.read()\n",
    "            \n",
    "            if success:\n",
    "                image = cv2.resize(image, (640, 360))\n",
    "                try:\n",
    "                    image = np.uint8(image)\n",
    "                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                except:\n",
    "                    break\n",
    "#                 print(self.image_num)\n",
    "                co_ordinates = self.face_co_ordinates(gray)\n",
    "\n",
    "                if len(co_ordinates) > 0:\n",
    "                    for co_ordinate in co_ordinates:\n",
    "                        if draw_face:\n",
    "                            color = self.colors()\n",
    "                            x,y,w,h = co_ordinate\n",
    "                            try:\n",
    "                                crop_image = self.crop_face(image, co_ordinate)\n",
    "                                name = os.path.join(self.output_dir, self.image_name + str(self.image_num) +'.jpg')\n",
    "                                cv2.imwrite(name, crop_image)\n",
    "                                self.image_num += 1\n",
    "                            except:\n",
    "                                print(traceback.print_exc(), exc_info=True)\n",
    "                            try:\n",
    "                                x_ = cv2.resize(cv2.cvtColor(crop_image, cv2.COLOR_BGR2GRAY), (2*16, 32))/255\n",
    "                                x_ = x_.astype(np.float32)\n",
    "                                x_ = torch.tensor(x_)\n",
    "                                x_ = x_.view((1,1,32,16*2))\n",
    "                                pred = model(x_)\n",
    "\n",
    "                                pred = int(pred.argmax().item())\n",
    "                                \n",
    "                                if pred == 1:\n",
    "#                                     print(\"true face detected ----------- \")\n",
    "                                    self.is_face = True\n",
    "                                    \n",
    "                            except:\n",
    "                                print(traceback.print_exc(), exc_info=True)\n",
    "                                \n",
    "                            if self.is_face:\n",
    "                                self.draw_rectangle(image, co_ordinate, color)\n",
    "                                x1, y1, w1, h1 = self.neck_cordinates(x,y,w,h)\n",
    "                                self.draw_rectangle(image, (x1, y1, w1, h1), color)\n",
    "                                x2, y2, w2, h2 = self.upper_half_torso_cordinates(x,y,w,h,h1)\n",
    "                                self.draw_rectangle(image, (x2, y2, w2, h2), color)\n",
    "    #                             print(\"888888888888888888888888\")\n",
    "                                x3, y3, w3, h3 = self.lower_half_torso_cordinates(x2, y2, w2, h2, h)\n",
    "                                self.draw_rectangle(image, (x3, y3, w3, h3), color)\n",
    "                                x4, y4, w4, h4 = self.legs_cordinates(x3, y3, w3, h3, h)\n",
    "                                self.draw_rectangle(image, (x4, y4, w4, h4), color)\n",
    "    #                             print(\"999999999999999999999999\")\n",
    "                                x5, y5, w5, h5 = self.foot_cordinates(x4, y4, w4, h4, h)\n",
    "                                self.draw_rectangle(image, (x5, y5, w5, h5), color)\n",
    "    #                             self.image_num += 1\n",
    "                image = self.resize_with_aspect_ratio(image, width=1280)\n",
    "                cv2.imshow('Fashion Show', image)\n",
    "    #                         cv2.waitKey(1)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_video_faces():\n",
    "#     classifier_path = \"/media/amit/CA301AE8301ADAF1/Documents/PROJECT/Face/HAARCASCADE/\"\n",
    "    classifier = os.listdir(classifier_path)\n",
    "    face_classifier = cv2.CascadeClassifier(os.path.join(classifier_path, classifier[0]))\n",
    "    \n",
    "    images_dir_path = './IMAGES/'\n",
    "    output_dir = './Fashion_Show/FACE_DATA01'\n",
    "    video_dir_path = img_path\n",
    "    image_num = 1\n",
    "    dir_num = 1\n",
    "    vid_num = 1\n",
    "    images_path = './None'\n",
    "    \n",
    "    video_dir = os.listdir(video_dir_path)\n",
    "    \n",
    "    for video in video_dir[1:]:\n",
    "        video_path = os.path.join(video_dir_path, video)\n",
    "        output_dir1 = os.path.join(output_dir, os.path.splitext(video)[0])\n",
    "        vf = VideoFace(video_path, face_classifier, images_path, output_dir1)\n",
    "        vf.image_num = image_num\n",
    "        vf.vid_num = vid_num\n",
    "        vf.get_video_face(draw_face=True)\n",
    "        \n",
    "        image_num = vf.image_num\n",
    "        vid_num += 1\n",
    "    cv2.destroyAllWindows()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Video Running --> F:\\Documents\\PROJECT\\VIDEOS\\Facevids\\Russian Beautiful Girls on Walking in Russia - Part 2.mp4\n",
      "1 Video Running --> F:\\Documents\\PROJECT\\VIDEOS\\Facevids\\Russian Beautiful Girls Walking Street - Part 1.mp4\n",
      "1 Video Running --> F:\\Documents\\PROJECT\\VIDEOS\\Facevids\\y2mate.com - M G ROAD CROWD WALKING  STOCK FOOTAGES_1080p.mp4\n",
      "1 Video Running --> F:\\Documents\\PROJECT\\VIDEOS\\Facevids\\y2mate.com - Street Style Highlights  Models Off Duty SS 2019_1080pFHR.mp4\n",
      "1 Video Running --> F:\\Documents\\PROJECT\\VIDEOS\\Facevids\\y2mate.com - WHAT EVERYONE IS WEARING IN PARIS  Paris Street Fashion_1080p.mp4\n"
     ]
    }
   ],
   "source": [
    "get_all_video_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_faces():\n",
    "    classifier_path = './HAARCASCADE/'\n",
    "    classifier = os.listdir(classifier_path)\n",
    "    face_classifier = cv2.CascadeClassifier(os.path.join(classifier_path, classifier[0]))\n",
    "    \n",
    "    images_dir_path = './MY/'\n",
    "    output_dir = './FACES2/'\n",
    "    image_num = 50000\n",
    "    dir_num = 1\n",
    "    \n",
    "    images_dirs = os.listdir(images_dir_path)\n",
    "    \n",
    "    for image_dir in images_dirs:\n",
    "        images_path = os.path.join(images_dir_path, image_dir)\n",
    "        fc = Faces(face_classifier, images_path, output_dir)\n",
    "        fc.image_num = image_num\n",
    "        fc.dir_num = dir_num\n",
    "        fc.all_faces()\n",
    "        image_num = fc.image_num\n",
    "        dir_num += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_all_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_face_path = './FINAL-FACES/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_face_images = os.listdir(final_face_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_name  = []\n",
    "imgs_shape = []\n",
    "for i in final_face_images:\n",
    "    img = cv2.imread(os.path.join(final_face_path, i))\n",
    "    imgs_name.append(i)\n",
    "    imgs_shape.append(img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(imgs_shape)), sorted(imgs_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'image': imgs_name,\n",
    "    'shape': imgs_shape,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(imgs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['shape']>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunny_img = cv2.imread(os.path.join(sunny_images_path, 'Image99.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sunny_images[51:200]:\n",
    "    sunny_img = cv2.imread(os.path.join(sunny_images_path, i))\n",
    "    \n",
    "    gray = cv2.cvtColor(sunny_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_classifier.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(sunny_img, (x,y), (x+w, y+h), (0, 255,0), 3)\n",
    "    cv2.imshow('sunny', sunny_img)\n",
    "    cv2.waitKey(1500)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunny_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = sunny_img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sunny_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'k/l/m/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.basename(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sunny_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(sunny_img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray)\n",
    "# gray = cv2.flip(gray, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_classifier.detectMultiScale(gray, 1.1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sunny_img.copy()\n",
    "# img = cv2.flip(img, 1)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255,0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
